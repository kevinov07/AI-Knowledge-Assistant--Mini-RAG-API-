# AI Knowledge Assistant - TODO

## Posibles bugs (por verificar)

### Carga de archivos (posible bug en frontend)

- **S√≠ntoma:** Al subir archivos una primera vez y luego volver a subir (otra tanda o los mismos), parece que se reenv√≠an tambi√©n los que ya se hab√≠an subido antes.
- **Hip√≥tesis:** Comportamiento del frontend (p. ej. el input de archivos no se limpia o se reutiliza la misma selecci√≥n). A√∫n no verificado del lado backend.
- **Qu√© comprobar:** Si el backend recibe en cada petici√≥n solo los archivos que el usuario eligi√≥ en esa acci√≥n, o si por alg√∫n motivo llegan duplicados/repetidos.

## Features pendientes

### üîî Notificaciones

- [ ] **Sistema de notificaciones toast/alert**
  - Notificaci√≥n de √©xito al cargar documentos correctamente
  - Notificaci√≥n de error cuando falla la carga
  - Mostrar detalles espec√≠ficos de los errores (qu√© documentos fallaron y por qu√©)
  - Indicador visual durante el proceso de carga
  - Lista de documentos procesados con su estado (exitoso/fallido)

### üìù Gesti√≥n de documentos

- [ ] **Crear documentos en la app**
  - Agregar funcionalidad para crear documentos directamente escribiendo texto en un input dentro de la aplicaci√≥n
  - Permitir editar y guardar documentos creados

- [ ] **Visualizaci√≥n de documentos en el frontend (preview por texto)**
  - Usar el texto plano que devuelve `GET /api/documents/{id}/text` para mostrar una vista previa del documento (solo visualizaci√≥n, no descarga del archivo original).
  - Variar la presentaci√≥n seg√∫n la extensi√≥n del archivo (`filename`): `.md` ‚Üí renderizar como Markdown; `.txt` ‚Üí texto con saltos de l√≠nea; `.pdf`/`.docx` ‚Üí mismo texto en vista tipo documento (legible); `.csv` ‚Üí opcionalmente parsear y mostrar como tabla.
  - Objetivo: que el usuario vea qu√© contenido est√° indexado sin guardar ni servir el binario original.

- [x] **Soporte para m√∫ltiples formatos**
  - ‚úÖ Formatos soportados en el backend (seg√∫n `DocumentProcessor`):
    - `.txt` ‚Äî texto plano
    - `.pdf` ‚Äî PDF
    - `.docx` ‚Äî Word
    - `.md` ‚Äî Markdown
    - `.csv` ‚Äî CSV (convertido a texto estructurado)
    - `.xlsx` ‚Äî Excel (nuevo)
    - `.xls` ‚Äî Excel (legacy)

### üìö Sistema de colecciones

- [ ] **Colecciones de documentos**
  - Permitir a los usuarios crear colecciones personalizadas de documentos
  - Caracter√≠sticas:
    - **Colecciones p√∫blicas**: accesibles para todos
    - **Colecciones privadas**: protegidas con clave/c√≥digo de acceso
    - Selector de colecci√≥n para elegir el contexto en las consultas

- [ ] **Backend para colecciones**
  - Implementar base de datos para gestionar colecciones
  - API endpoints para CRUD de colecciones
  - Validaci√≥n de contrase√±a simple para colecciones privadas (sin sistema de usuarios)
  - L√≥gica para seleccionar contexto de colecciones espec√≠ficas

### üìÑ Filtro por documento / nombre en contexto (RAG)

- [ ] **Incluir nombre del documento en el contexto enviado al LLM**
  - Prefijar cada fragmento con el `filename` al armar el contexto (ej. `"[kevin-cv-espa√±ol.pdf]\n" + texto`), para que el modelo sepa de qu√© documento viene cada parte y pueda priorizar o citar mejor.
- [ ] **Filtro por documento cuando el usuario menciona uno**
  - Detectar en la pregunta menci√≥n a un documento (nombre de archivo, "el CV", "en el documento X", coincidencia con `documents.filename`).
  - Restringir la b√∫squeda sem√°ntica a ese documento: en `similarity_search_chunks_pgvector` a√±adir filtro `WHERE document_id = :doc_id` (o lista de candidatos) para que los k chunks salgan solo de ese doc.

### üîÑ Reintentar respuesta (mejor contexto)

- [ ] **Bot√≥n "Reintentar" en el frontend**
  - Si el usuario no est√° satisfecho con la respuesta, poder pulsar "Reintentar" sin cambiar la pregunta.
  - **Comportamiento:** Al reintentar, el frontend vuelve a llamar a `POST /api/ask` con la misma pregunta pero con m√°s contexto (p. ej. `k` mayor o un par√°metro opcional para ampliar el `window`), para que el modelo reciba m√°s chunks y pueda dar una respuesta m√°s completa.
  - Backend: opcionalmente aceptar un par√°metro tipo `retry_with_more_context=true` que aumente `k` o el window interno; o que el frontend env√≠e directamente un `k` mayor en el body.

### üí¨ Historial de chat (contexto de conversaci√≥n)

- [ ] **Guardar y usar historial de chat para que el LLM tenga contexto**
  - Hoy cada `POST /api/ask` es una petici√≥n aislada: no se env√≠a al LLM la pregunta ni la respuesta anteriores, por eso preguntas de seguimiento ("ampl√≠a detalles", "¬øy las tecnolog√≠as?") no tienen contexto.
  - Objetivo: que el modelo reciba las √∫ltimas N vueltas (pregunta + respuesta) adem√°s de la pregunta actual y el contexto RAG, para poder responder como en una conversaci√≥n.
  - Backend: aceptar en el body un historial opcional (lista de `{ role: "user"|"assistant", content: string }`) o un `session_id` y recuperar historial desde BD; incluir ese historial en el prompt que se env√≠a a Groq (respetando l√≠mite de contexto del modelo).
  - Frontend: mantener en estado (o en BD/localStorage) el historial del chat y enviarlo en cada nueva pregunta; opci√≥n de "nueva conversaci√≥n" para limpiar historial.

## Configuraci√≥n Completada

- [x] Variables de entorno para API URL
- [x] Build con SSR funcionando
- [x] Configuraci√≥n de despliegue en Vercel